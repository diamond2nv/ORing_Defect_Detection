{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.optimizers import Adam ,SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\SmallWindow\\\\NG\\\\100.05925293681634_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\100.15643469971401_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\100.26791675545138_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\100.35256973863001_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\100.45269591426657_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\101.06881326728409_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\101.089443378119_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\101.19477353891503_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\101.4390546451655_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\101.49469174892904_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\101.60597804935004_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\101.82961222091657_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\101.86642535534564_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\101.99395976679448_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\102.0796754910333_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\102.15260128163354_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\102.61508483928817_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\102.88534367942556_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\102.98616982412192_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\103.10795454545455_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\103.28361449807917_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\103.38605648909547_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\103.48053084439259_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\103.63420837496594_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\103.80033712600084_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\103.99401974205634_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\104.09876187733947_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\104.2978539950182_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\105.13614326704264_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\105.21417357174008_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\105.41262866429905_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\105.46785714285714_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\105.63399675305153_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\105.68344662135146_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\105.763034787786_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\106.25780939116594_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\106.38359524025797_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\107.04216170749659_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\107.25604337006754_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\107.30731102850062_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\109.59596861644447_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\110.18086324153256_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\110.9712449255751_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\111.00461784940157_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\84.95273591530275_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\85.07253479709861_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\88.210338327215_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\88.27903770593507_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\90.62603352802851_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\91.46760563380282_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\93.53679690131358_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\93.72350433632221_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\93.94848127782141_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\94.20602662929223_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\94.91571316272163_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\95.1543174420831_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\95.4719893292683_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\95.95888673332338_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\96.08824493542254_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\96.1471274586065_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\97.04827586206896_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\97.38991382629038_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\97.44973062577704_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\97.70453329256173_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\98.10999772261444_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\98.86360659641603_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\99.18707418019738_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\99.5594473703196_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\99.58783429470373_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\99.85335442449056_Detect.jpg']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = ['.\\\\SmallWindow\\\\OK','.\\\\SmallWindow\\\\NG']\n",
    "files = [[],[]]\n",
    "# r=root, d=directories, f = files\n",
    "for index in range(2):\n",
    "    for r, d, f in os.walk(path[index]):\n",
    "        for file in f:\n",
    "            files[index].append(os.path.join(r, file))\n",
    "            \n",
    "files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 224, 224, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "images = []\n",
    "\n",
    "\n",
    "\n",
    "for index in range(2):\n",
    "    for j in range(len(files[index])):\n",
    "        img = cv2.imread(files[index][j],1)\n",
    "        images.append(cv2.resize(img,(224,224)))\n",
    "        #images.append(img)\n",
    "        labels.append(index)\n",
    "np.array(labels).shape\n",
    "\n",
    "train_x, val_x, train_y, val_y =train_test_split( images , labels ,test_size = 0.2, random_state = 4)\n",
    "train_x, train_y = shuffle(train_x, train_y, random_state=4)\n",
    "np.array(train_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata_length = len(images)\\n\\ndata_x = np.array(images)\\ndata_y = np.array(labels)\\n\\ndata_x = data_x.reshape(data_x.shape[0],data_x.shape[1],data_x.shape[2],1)        \\n\\ndata_y = np_utils.to_categorical(data_y, 2)\\n\\n\\nX, Y = shuffle(data_x, data_y, random_state=4)\\n\\nx_train,x_test,y_train,y_test =train_test_split( X , Y ,test_size = 0.1, random_state = 4)\\n\\n\\nprint(\"xtrain長度:\", len(y_train))\\n#print(\"y長度:\", len(y_test))\\nX.shape\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data_length = len(images)\n",
    "\n",
    "data_x = np.array(images)\n",
    "data_y = np.array(labels)\n",
    "\n",
    "data_x = data_x.reshape(data_x.shape[0],data_x.shape[1],data_x.shape[2],1)        \n",
    "\n",
    "data_y = np_utils.to_categorical(data_y, 2)\n",
    "\n",
    "\n",
    "X, Y = shuffle(data_x, data_y, random_state=4)\n",
    "\n",
    "x_train,x_test,y_train,y_test =train_test_split( X , Y ,test_size = 0.1, random_state = 4)\n",
    "\n",
    "\n",
    "print(\"xtrain長度:\", len(y_train))\n",
    "#print(\"y長度:\", len(y_test))\n",
    "X.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel1 = Sequential()\\n\\nmodel1.add(Conv2D(128, (3,3), padding='same', input_shape=(150,150,1))) #4個filter，都是5*5\\nmodel1.add(Activation('relu'))\\nmodel1.add(MaxPool2D(pool_size=(2,2)))\\n\\nmodel1.add(Conv2D(256, (3,3), padding='same'))\\nmodel1.add(Activation('relu'))\\nmodel1.add(MaxPool2D(pool_size=(2,2)))\\n\\nmodel1.add(Conv2D(256, (3,3), padding='same'))\\nmodel1.add(Activation('relu'))\\nmodel1.add(MaxPool2D(pool_size=(2,2)))\\n\\nmodel1.add(Conv2D(512, (3,3), padding='same'))\\nmodel1.add(Activation('relu'))\\nmodel1.add(MaxPool2D(pool_size=(2,2)))\\n\\nmodel1.add(Flatten())\\nmodel1.add(Dense(1024))#拉平完送進最後一個普通NN\\nmodel1.add(Activation('relu'))\\n\\nmodel1.add(Dense(2))\\nmodel1.add(Activation('sigmoid'))\\n\\nmodel1.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\\nmodel1.summary()\\nmodel1_out=model1.fit(x_train, y_train, batch_size=3, epochs=30,verbose =1,validation_data = (x_test,y_test))\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Conv2D(128, (3,3), padding='same', input_shape=(150,150,1))) #4個filter，都是5*5\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model1.add(Conv2D(256, (3,3), padding='same'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model1.add(Conv2D(256, (3,3), padding='same'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model1.add(Conv2D(512, (3,3), padding='same'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(1024))#拉平完送進最後一個普通NN\n",
    "model1.add(Activation('relu'))\n",
    "\n",
    "model1.add(Dense(2))\n",
    "model1.add(Activation('sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model1.summary()\n",
    "model1_out=model1.fit(x_train, y_train, batch_size=3, epochs=30,verbose =1,validation_data = (x_test,y_test))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): ConvBNReLU(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): ConvBNReLU(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved to ./model/model_best_densenet161.pth\n",
      "[001/50000] 1.20 sec(s) Train Acc: 0.305085 Loss: 0.066896 | Val Acc: 0.755556 loss: 0.049280\n",
      "[002/50000] 1.20 sec(s) Train Acc: 0.666667 Loss: 0.026722 | Val Acc: 0.755556 loss: 0.022238\n",
      "model saved to ./model/model_best_densenet161.pth\n",
      "[003/50000] 1.24 sec(s) Train Acc: 0.745763 Loss: 0.018993 | Val Acc: 0.866667 loss: 0.022835\n",
      "model saved to ./model/model_best_densenet161.pth\n",
      "[004/50000] 1.13 sec(s) Train Acc: 0.802260 Loss: 0.017125 | Val Acc: 0.888889 loss: 0.015284\n",
      "[005/50000] 1.18 sec(s) Train Acc: 0.790960 Loss: 0.014683 | Val Acc: 0.866667 loss: 0.013996\n",
      "[006/50000] 1.13 sec(s) Train Acc: 0.858757 Loss: 0.011973 | Val Acc: 0.888889 loss: 0.012389\n",
      "[007/50000] 1.12 sec(s) Train Acc: 0.881356 Loss: 0.010703 | Val Acc: 0.866667 loss: 0.013554\n",
      "model saved to ./model/model_best_densenet161.pth\n",
      "[008/50000] 1.19 sec(s) Train Acc: 0.920904 Loss: 0.009098 | Val Acc: 0.911111 loss: 0.011178\n",
      "[009/50000] 1.11 sec(s) Train Acc: 0.892655 Loss: 0.008868 | Val Acc: 0.911111 loss: 0.009346\n",
      "model saved to ./model/model_best_densenet161.pth\n",
      "[010/50000] 1.13 sec(s) Train Acc: 0.887006 Loss: 0.009557 | Val Acc: 0.933333 loss: 0.007378\n",
      "[011/50000] 1.18 sec(s) Train Acc: 0.898305 Loss: 0.007998 | Val Acc: 0.933333 loss: 0.008047\n",
      "[012/50000] 1.15 sec(s) Train Acc: 0.898305 Loss: 0.008857 | Val Acc: 0.933333 loss: 0.009703\n",
      "[013/50000] 1.09 sec(s) Train Acc: 0.960452 Loss: 0.005025 | Val Acc: 0.933333 loss: 0.007694\n",
      "[014/50000] 1.10 sec(s) Train Acc: 0.937853 Loss: 0.005514 | Val Acc: 0.933333 loss: 0.008194\n",
      "[015/50000] 1.13 sec(s) Train Acc: 0.954802 Loss: 0.005192 | Val Acc: 0.911111 loss: 0.012589\n",
      "[016/50000] 1.09 sec(s) Train Acc: 0.937853 Loss: 0.005557 | Val Acc: 0.866667 loss: 0.016941\n",
      "[017/50000] 1.14 sec(s) Train Acc: 0.949153 Loss: 0.005810 | Val Acc: 0.911111 loss: 0.010073\n",
      "[018/50000] 1.12 sec(s) Train Acc: 0.943503 Loss: 0.004665 | Val Acc: 0.933333 loss: 0.007412\n",
      "[019/50000] 1.12 sec(s) Train Acc: 0.943503 Loss: 0.006593 | Val Acc: 0.933333 loss: 0.006934\n",
      "[020/50000] 1.11 sec(s) Train Acc: 0.960452 Loss: 0.004180 | Val Acc: 0.933333 loss: 0.008670\n",
      "[021/50000] 1.15 sec(s) Train Acc: 0.977401 Loss: 0.002677 | Val Acc: 0.933333 loss: 0.009760\n",
      "[022/50000] 1.14 sec(s) Train Acc: 0.971751 Loss: 0.003574 | Val Acc: 0.933333 loss: 0.008410\n",
      "[023/50000] 1.12 sec(s) Train Acc: 0.937853 Loss: 0.004807 | Val Acc: 0.933333 loss: 0.008751\n",
      "[024/50000] 1.11 sec(s) Train Acc: 0.971751 Loss: 0.002589 | Val Acc: 0.933333 loss: 0.012888\n",
      "[025/50000] 1.14 sec(s) Train Acc: 0.960452 Loss: 0.002971 | Val Acc: 0.888889 loss: 0.012500\n",
      "[026/50000] 1.09 sec(s) Train Acc: 0.983051 Loss: 0.002080 | Val Acc: 0.911111 loss: 0.011784\n",
      "[027/50000] 1.13 sec(s) Train Acc: 0.988701 Loss: 0.002406 | Val Acc: 0.888889 loss: 0.013469\n",
      "[028/50000] 1.15 sec(s) Train Acc: 0.960452 Loss: 0.003088 | Val Acc: 0.933333 loss: 0.011038\n",
      "[029/50000] 1.07 sec(s) Train Acc: 0.983051 Loss: 0.002531 | Val Acc: 0.933333 loss: 0.012482\n",
      "[030/50000] 1.05 sec(s) Train Acc: 0.971751 Loss: 0.002247 | Val Acc: 0.933333 loss: 0.014686\n",
      "[031/50000] 1.12 sec(s) Train Acc: 0.960452 Loss: 0.003504 | Val Acc: 0.933333 loss: 0.010889\n",
      "[032/50000] 1.14 sec(s) Train Acc: 0.960452 Loss: 0.002984 | Val Acc: 0.866667 loss: 0.010804\n",
      "[033/50000] 1.08 sec(s) Train Acc: 0.949153 Loss: 0.003976 | Val Acc: 0.911111 loss: 0.010027\n",
      "[034/50000] 1.08 sec(s) Train Acc: 0.971751 Loss: 0.003345 | Val Acc: 0.911111 loss: 0.008308\n",
      "[035/50000] 1.12 sec(s) Train Acc: 0.971751 Loss: 0.002647 | Val Acc: 0.911111 loss: 0.008416\n",
      "[036/50000] 1.05 sec(s) Train Acc: 0.977401 Loss: 0.002101 | Val Acc: 0.911111 loss: 0.010173\n",
      "model saved to ./model/model_best_densenet161.pth\n",
      "[037/50000] 1.18 sec(s) Train Acc: 0.977401 Loss: 0.003144 | Val Acc: 0.955556 loss: 0.006189\n",
      "[038/50000] 1.10 sec(s) Train Acc: 0.960452 Loss: 0.003034 | Val Acc: 0.911111 loss: 0.015216\n",
      "[039/50000] 1.10 sec(s) Train Acc: 0.971751 Loss: 0.002247 | Val Acc: 0.866667 loss: 0.018209\n",
      "[040/50000] 1.15 sec(s) Train Acc: 0.960452 Loss: 0.002573 | Val Acc: 0.866667 loss: 0.015445\n",
      "[041/50000] 1.13 sec(s) Train Acc: 0.966102 Loss: 0.001862 | Val Acc: 0.933333 loss: 0.009253\n",
      "[042/50000] 1.18 sec(s) Train Acc: 0.971751 Loss: 0.002121 | Val Acc: 0.933333 loss: 0.005898\n",
      "[043/50000] 1.17 sec(s) Train Acc: 0.988701 Loss: 0.001799 | Val Acc: 0.911111 loss: 0.007038\n",
      "[044/50000] 1.30 sec(s) Train Acc: 0.949153 Loss: 0.003783 | Val Acc: 0.955556 loss: 0.005054\n",
      "[045/50000] 1.17 sec(s) Train Acc: 0.994350 Loss: 0.001028 | Val Acc: 0.955556 loss: 0.007133\n",
      "[046/50000] 1.26 sec(s) Train Acc: 0.977401 Loss: 0.001965 | Val Acc: 0.955556 loss: 0.005985\n",
      "[047/50000] 1.72 sec(s) Train Acc: 0.983051 Loss: 0.001305 | Val Acc: 0.933333 loss: 0.008320\n",
      "[048/50000] 1.23 sec(s) Train Acc: 0.977401 Loss: 0.002592 | Val Acc: 0.955556 loss: 0.004655\n",
      "model saved to ./model/model_best_densenet161.pth\n",
      "[049/50000] 1.16 sec(s) Train Acc: 0.977401 Loss: 0.001837 | Val Acc: 0.977778 loss: 0.003473\n",
      "[050/50000] 1.14 sec(s) Train Acc: 0.983051 Loss: 0.001844 | Val Acc: 0.977778 loss: 0.003695\n",
      "[051/50000] 1.10 sec(s) Train Acc: 0.994350 Loss: 0.001399 | Val Acc: 0.955556 loss: 0.003742\n",
      "[052/50000] 1.16 sec(s) Train Acc: 0.966102 Loss: 0.003700 | Val Acc: 0.955556 loss: 0.003890\n",
      "[053/50000] 1.18 sec(s) Train Acc: 0.994350 Loss: 0.000881 | Val Acc: 0.933333 loss: 0.004499\n",
      "[054/50000] 1.25 sec(s) Train Acc: 0.988701 Loss: 0.001294 | Val Acc: 0.955556 loss: 0.005170\n",
      "[055/50000] 1.23 sec(s) Train Acc: 0.988701 Loss: 0.000786 | Val Acc: 0.933333 loss: 0.005449\n",
      "[056/50000] 1.20 sec(s) Train Acc: 0.971751 Loss: 0.001989 | Val Acc: 0.955556 loss: 0.005089\n",
      "[057/50000] 1.24 sec(s) Train Acc: 0.977401 Loss: 0.001716 | Val Acc: 0.933333 loss: 0.005239\n",
      "[058/50000] 1.14 sec(s) Train Acc: 0.971751 Loss: 0.002419 | Val Acc: 0.955556 loss: 0.004813\n",
      "[059/50000] 1.12 sec(s) Train Acc: 0.994350 Loss: 0.001053 | Val Acc: 0.977778 loss: 0.004405\n",
      "[060/50000] 1.16 sec(s) Train Acc: 0.954802 Loss: 0.002806 | Val Acc: 0.977778 loss: 0.003453\n",
      "[061/50000] 1.19 sec(s) Train Acc: 0.994350 Loss: 0.000780 | Val Acc: 0.888889 loss: 0.007649\n",
      "[062/50000] 1.12 sec(s) Train Acc: 0.971751 Loss: 0.001813 | Val Acc: 0.933333 loss: 0.005995\n",
      "[063/50000] 1.08 sec(s) Train Acc: 0.983051 Loss: 0.001334 | Val Acc: 0.933333 loss: 0.005425\n",
      "[064/50000] 1.15 sec(s) Train Acc: 0.988701 Loss: 0.001172 | Val Acc: 0.955556 loss: 0.004542\n",
      "[065/50000] 1.12 sec(s) Train Acc: 0.994350 Loss: 0.000980 | Val Acc: 0.955556 loss: 0.005343\n",
      "[066/50000] 1.21 sec(s) Train Acc: 0.977401 Loss: 0.003121 | Val Acc: 0.955556 loss: 0.007065\n",
      "[067/50000] 1.16 sec(s) Train Acc: 0.988701 Loss: 0.001008 | Val Acc: 0.933333 loss: 0.007826\n",
      "[068/50000] 1.17 sec(s) Train Acc: 0.994350 Loss: 0.000832 | Val Acc: 0.955556 loss: 0.003563\n",
      "model saved to ./model/model_best_densenet161.pth\n",
      "[069/50000] 1.24 sec(s) Train Acc: 0.977401 Loss: 0.001899 | Val Acc: 1.000000 loss: 0.002827\n",
      "[070/50000] 1.29 sec(s) Train Acc: 0.988701 Loss: 0.001654 | Val Acc: 0.955556 loss: 0.004452\n",
      "[071/50000] 1.29 sec(s) Train Acc: 0.983051 Loss: 0.001259 | Val Acc: 0.955556 loss: 0.003976\n",
      "[072/50000] 1.28 sec(s) Train Acc: 0.988701 Loss: 0.000919 | Val Acc: 0.955556 loss: 0.003023\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-7cd736e3b4ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 用 optimizer 將 model 參數的 gradient 歸零\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;31m#print(type(data))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mtrain_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 利用 model 得到預測的機率分佈 這邊實際上就是去呼叫 model 的 forward 函數\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mbatch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 利用 back propagation 算出每個參數的 gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\torchvision\\models\\mobilenet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\torchvision\\models\\mobilenet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;31m# This exists since TorchScript doesn't support inheritance, so the superclass method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;31m# (this one) needs to have a name other than `forward` that can be accessed in a subclass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\torchvision\\models\\mobilenet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_res_connect\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   1668\u001b[0m     return torch.batch_norm(\n\u001b[0;32m   1669\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1670\u001b[1;33m         \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1671\u001b[0m     )\n\u001b[0;32m   1672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import需要的套件\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import time\n",
    "import torchvision\n",
    "\n",
    "\n",
    "\n",
    "def readfile(path, label):\n",
    "    # label 是一個 boolean variable，代表需不需要回傳 y 值\n",
    "    image_dir = sorted(os.listdir(path))\n",
    "    x = np.zeros((len(image_dir), 224, 224, 3), dtype=np.uint8)\n",
    "    y = np.zeros((len(image_dir)), dtype=np.uint8)\n",
    "    for i, file in enumerate(image_dir):\n",
    "        img = cv2.imread(os.path.join(path, file))\n",
    "        #resize\n",
    "        x[i, :, :] = cv2.resize(img,(224, 224))\n",
    "        \n",
    "        if label:\n",
    "            y[i] = int(file.split(\"_\")[0])\n",
    "    if label:\n",
    "        return x, y\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "#分別將 training set、validation set、testing set 用 readfile 函式讀進來\n",
    "'''\n",
    "train_x = np.load('train_x_224.npy')\n",
    "train_y = np.load('train_y_224.npy')\n",
    "val_x = np.load('val_x_224.npy')\n",
    "val_y = np.load('val_y_224.npy')\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "#training 時做 data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(), #隨機將圖片水平翻轉\n",
    "    transforms.RandomRotation(45), #隨機旋轉圖片\n",
    "    transforms.RandomRotation(15), #隨機旋轉圖片\n",
    "    transforms.ToTensor(), #將圖片轉成 Tensor，並把數值normalize到[0,1](data normalization)\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "#testing 時不需做 data augmentation\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                                    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, x, y=None, transform=None):\n",
    "        self.x = x\n",
    "        # label is required to be a LongTensor\n",
    "        self.y = y\n",
    "        if y is not None:\n",
    "            self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, index):\n",
    "        X = self.x[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        if self.y is not None:\n",
    "            Y = self.y[index]\n",
    "            return X, Y\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "batch_size = 32\n",
    "train_set = ImgDataset(train_x, train_y, train_transform)\n",
    "val_set = ImgDataset(val_x, val_y, test_transform)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "#original_model = torchvision.models.resnet50(pretrained = True)\n",
    "#original_model = torchvision.models.googlenet(pretrained=True)\n",
    "#original_model = torchvision.models.densenet121(pretrained=True)#batch size 200\n",
    "#original_model = torchvision.models.resnext101_32x8d(pretrained=True)#batch_size = 96\n",
    "#original_model = torchvision.models.wide_resnet101_2(pretrained=True)#batch_size = 72\n",
    "model = torchvision.models.mobilenet_v2(pretrained=True)#batch size 200\n",
    "#model = torchvision.models.mobilenet_v2(pretrained = True)\n",
    "print(model)\n",
    "\n",
    "#model = original_model\n",
    "model.classifier = nn.Sequential(\n",
    "                    nn.Linear(1280,11),\n",
    "                    #nn.Dropout(0.3),\n",
    "                    #nn.ReLU(),\n",
    "                    #nn.Linear(1024,512),\n",
    "                    #nn.Dropout(0.25),\n",
    "                    #nn.ReLU(),\n",
    "                    #nn.Linear(512, 11),\n",
    "                    )\n",
    "#model = Classifier()\n",
    "#model.load_state_dict(torch.load('./model/densenet161_819534.pth'))\n",
    "model.cuda()\n",
    "\n",
    "loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.002) # optimizer 使用 Adam\n",
    "#optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001, betas=[0.9, 0.999])\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9,weight_decay = 0.0005)\n",
    "num_epoch = 50000\n",
    "\n",
    "best_val_acc = 0\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    model.train() # 確保 model 是在 train model (開啟 Dropout 等...)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad() # 用 optimizer 將 model 參數的 gradient 歸零\n",
    "        #print(type(data))\n",
    "        train_pred = model(data[0].cuda()) # 利用 model 得到預測的機率分佈 這邊實際上就是去呼叫 model 的 forward 函數\n",
    "        batch_loss = loss(train_pred, data[1].cuda()) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\n",
    "        batch_loss.backward() # 利用 back propagation 算出每個參數的 gradient\n",
    "        optimizer.step() # 以 optimizer 用 gradient 更新參數值\n",
    "\n",
    "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "        train_loss += batch_loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            val_pred = model(data[0].cuda())\n",
    "            batch_loss = loss(val_pred, data[1].cuda())\n",
    "\n",
    "            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "            val_loss += batch_loss.item()\n",
    "\n",
    "        final_train_acc = train_acc/train_set.__len__()\n",
    "        final_val_acc = val_acc/val_set.__len__()\n",
    "        #if (final_train_acc > 0.95 and final_val_acc > best_val_acc):\n",
    "        if (final_val_acc > best_val_acc):\n",
    "            best_val_acc = final_val_acc\n",
    "            #print(\"------: \", train_acc/train_set.__len__())\n",
    "            #checkpoint_path = './model/model_{}_acc_{}.pth'.format(epoch+1,best_val_acc) \n",
    "            checkpoint_path = './model/model_best_densenet161.pth' \n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print('model saved to %s' % checkpoint_path)\n",
    "        \n",
    "        #將結果 print 出來\n",
    "        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n",
    "            (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
    "             train_acc/train_set.__len__(), train_loss/train_set.__len__(), val_acc/val_set.__len__(), val_loss/val_set.__len__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
