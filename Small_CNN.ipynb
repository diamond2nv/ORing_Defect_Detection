{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.optimizers import Adam ,SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\SmallWindow\\\\NG\\\\100.15643469971401_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\100.26791675545138_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\100.35256973863001_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\100.45269591426657_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\101.06881326728409_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\101.089443378119_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\101.19477353891503_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\101.4390546451655_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\101.60597804935004_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\101.82961222091657_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\101.86642535534564_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\101.99395976679448_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\102.15260128163354_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\103.10795454545455_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\103.28361449807917_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\103.38605648909547_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\103.48053084439259_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\103.63420837496594_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\103.80033712600084_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\103.99401974205634_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\104.09876187733947_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\104.2978539950182_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\105.13614326704264_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\105.21417357174008_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\105.41262866429905_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\105.46785714285714_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\105.63399675305153_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\105.68344662135146_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\105.763034787786_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\106.38359524025797_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\107.04216170749659_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\107.25604337006754_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\107.30731102850062_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\110.9712449255751_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\111.00461784940157_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\84.95273591530275_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\85.07253479709861_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\88.210338327215_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\88.27903770593507_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\90.62603352802851_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\91.46760563380282_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\94.20602662929223_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\94.91571316272163_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\95.1543174420831_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\95.95888673332338_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\96.08824493542254_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\96.1471274586065_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\97.38991382629038_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\97.44973062577704_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\97.70453329256173_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\98.10999772261444_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\99.18707418019738_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\99.58783429470373_Detect.jpg',\n",
       " '.\\\\SmallWindow\\\\NG\\\\99.85335442449056_Detect.jpg']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = ['.\\\\SmallWindow\\\\OK','.\\\\SmallWindow\\\\NG']\n",
    "files = [[],[]]\n",
    "# r=root, d=directories, f = files\n",
    "for index in range(2):\n",
    "    for r, d, f in os.walk(path[index]):\n",
    "        for file in f:\n",
    "            files[index].append(os.path.join(r, file))\n",
    "            \n",
    "files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173, 224, 224, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "images = []\n",
    "\n",
    "\n",
    "\n",
    "for index in range(2):\n",
    "    for j in range(len(files[index])):\n",
    "        img = cv2.imread(files[index][j],1)\n",
    "        images.append(cv2.resize(img,(224,224)))\n",
    "        #images.append(img)\n",
    "        labels.append(index)\n",
    "np.array(labels).shape\n",
    "\n",
    "train_x, val_x, train_y, val_y =train_test_split( images , labels ,test_size = 0.1, random_state = 4)\n",
    "train_x, train_y = shuffle(train_x, train_y, random_state=4)\n",
    "np.array(train_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata_length = len(images)\\n\\ndata_x = np.array(images)\\ndata_y = np.array(labels)\\n\\ndata_x = data_x.reshape(data_x.shape[0],data_x.shape[1],data_x.shape[2],1)        \\n\\ndata_y = np_utils.to_categorical(data_y, 2)\\n\\n\\nX, Y = shuffle(data_x, data_y, random_state=4)\\n\\nx_train,x_test,y_train,y_test =train_test_split( X , Y ,test_size = 0.1, random_state = 4)\\n\\n\\nprint(\"xtrain長度:\", len(y_train))\\n#print(\"y長度:\", len(y_test))\\nX.shape\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data_length = len(images)\n",
    "\n",
    "data_x = np.array(images)\n",
    "data_y = np.array(labels)\n",
    "\n",
    "data_x = data_x.reshape(data_x.shape[0],data_x.shape[1],data_x.shape[2],1)        \n",
    "\n",
    "data_y = np_utils.to_categorical(data_y, 2)\n",
    "\n",
    "\n",
    "X, Y = shuffle(data_x, data_y, random_state=4)\n",
    "\n",
    "x_train,x_test,y_train,y_test =train_test_split( X , Y ,test_size = 0.1, random_state = 4)\n",
    "\n",
    "\n",
    "print(\"xtrain長度:\", len(y_train))\n",
    "#print(\"y長度:\", len(y_test))\n",
    "X.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel1 = Sequential()\\n\\nmodel1.add(Conv2D(128, (3,3), padding='same', input_shape=(150,150,1))) #4個filter，都是5*5\\nmodel1.add(Activation('relu'))\\nmodel1.add(MaxPool2D(pool_size=(2,2)))\\n\\nmodel1.add(Conv2D(256, (3,3), padding='same'))\\nmodel1.add(Activation('relu'))\\nmodel1.add(MaxPool2D(pool_size=(2,2)))\\n\\nmodel1.add(Conv2D(256, (3,3), padding='same'))\\nmodel1.add(Activation('relu'))\\nmodel1.add(MaxPool2D(pool_size=(2,2)))\\n\\nmodel1.add(Conv2D(512, (3,3), padding='same'))\\nmodel1.add(Activation('relu'))\\nmodel1.add(MaxPool2D(pool_size=(2,2)))\\n\\nmodel1.add(Flatten())\\nmodel1.add(Dense(1024))#拉平完送進最後一個普通NN\\nmodel1.add(Activation('relu'))\\n\\nmodel1.add(Dense(2))\\nmodel1.add(Activation('sigmoid'))\\n\\nmodel1.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\\nmodel1.summary()\\nmodel1_out=model1.fit(x_train, y_train, batch_size=3, epochs=30,verbose =1,validation_data = (x_test,y_test))\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Conv2D(128, (3,3), padding='same', input_shape=(150,150,1))) #4個filter，都是5*5\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model1.add(Conv2D(256, (3,3), padding='same'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model1.add(Conv2D(256, (3,3), padding='same'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model1.add(Conv2D(512, (3,3), padding='same'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(1024))#拉平完送進最後一個普通NN\n",
    "model1.add(Activation('relu'))\n",
    "\n",
    "model1.add(Dense(2))\n",
    "model1.add(Activation('sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model1.summary()\n",
    "model1_out=model1.fit(x_train, y_train, batch_size=3, epochs=30,verbose =1,validation_data = (x_test,y_test))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): ConvBNReLU(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): ConvBNReLU(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved to ./model/model_best_densenet161.pth\n",
      "[001/50000] 2.28 sec(s) Train Acc: 0.739884 Loss: 0.084903 | Val Acc: 0.500000 loss: 0.137678\n",
      "[002/50000] 2.29 sec(s) Train Acc: 0.757225 Loss: 0.064110 | Val Acc: 0.500000 loss: 0.132761\n",
      "model saved to ./model/model_best_densenet161.pth\n",
      "[003/50000] 2.24 sec(s) Train Acc: 0.803468 Loss: 0.056537 | Val Acc: 0.650000 loss: 0.103394\n",
      "model saved to ./model/model_best_densenet161.pth\n",
      "[004/50000] 2.32 sec(s) Train Acc: 0.786127 Loss: 0.056821 | Val Acc: 0.750000 loss: 0.090005\n",
      "[005/50000] 2.21 sec(s) Train Acc: 0.803468 Loss: 0.060275 | Val Acc: 0.650000 loss: 0.094145\n",
      "[006/50000] 2.19 sec(s) Train Acc: 0.849711 Loss: 0.047069 | Val Acc: 0.700000 loss: 0.086274\n",
      "[007/50000] 2.28 sec(s) Train Acc: 0.849711 Loss: 0.044388 | Val Acc: 0.650000 loss: 0.103705\n",
      "[008/50000] 2.54 sec(s) Train Acc: 0.797688 Loss: 0.061272 | Val Acc: 0.700000 loss: 0.087374\n",
      "[009/50000] 2.33 sec(s) Train Acc: 0.843931 Loss: 0.041975 | Val Acc: 0.700000 loss: 0.086153\n",
      "[010/50000] 2.26 sec(s) Train Acc: 0.895954 Loss: 0.046254 | Val Acc: 0.750000 loss: 0.080969\n",
      "[011/50000] 2.24 sec(s) Train Acc: 0.878613 Loss: 0.042102 | Val Acc: 0.650000 loss: 0.079854\n",
      "[012/50000] 2.24 sec(s) Train Acc: 0.843931 Loss: 0.051012 | Val Acc: 0.600000 loss: 0.085170\n",
      "[013/50000] 2.22 sec(s) Train Acc: 0.861272 Loss: 0.043584 | Val Acc: 0.650000 loss: 0.102872\n",
      "[014/50000] 2.20 sec(s) Train Acc: 0.843931 Loss: 0.046687 | Val Acc: 0.650000 loss: 0.113554\n",
      "[015/50000] 2.17 sec(s) Train Acc: 0.861272 Loss: 0.040311 | Val Acc: 0.650000 loss: 0.081402\n",
      "[016/50000] 2.22 sec(s) Train Acc: 0.878613 Loss: 0.038575 | Val Acc: 0.750000 loss: 0.077595\n",
      "[017/50000] 2.20 sec(s) Train Acc: 0.890173 Loss: 0.039814 | Val Acc: 0.750000 loss: 0.076942\n",
      "[018/50000] 2.13 sec(s) Train Acc: 0.843931 Loss: 0.040754 | Val Acc: 0.750000 loss: 0.079822\n",
      "[019/50000] 2.23 sec(s) Train Acc: 0.826590 Loss: 0.048865 | Val Acc: 0.600000 loss: 0.093777\n",
      "[020/50000] 2.14 sec(s) Train Acc: 0.855491 Loss: 0.041459 | Val Acc: 0.750000 loss: 0.074727\n",
      "[021/50000] 2.25 sec(s) Train Acc: 0.901734 Loss: 0.037856 | Val Acc: 0.700000 loss: 0.075034\n",
      "[022/50000] 2.23 sec(s) Train Acc: 0.884393 Loss: 0.039017 | Val Acc: 0.750000 loss: 0.077661\n",
      "model saved to ./model/model_best_densenet161.pth\n",
      "[023/50000] 2.27 sec(s) Train Acc: 0.838150 Loss: 0.048693 | Val Acc: 0.800000 loss: 0.072552\n",
      "[024/50000] 2.21 sec(s) Train Acc: 0.895954 Loss: 0.035663 | Val Acc: 0.650000 loss: 0.100347\n",
      "[025/50000] 2.17 sec(s) Train Acc: 0.878613 Loss: 0.040612 | Val Acc: 0.650000 loss: 0.089641\n",
      "[026/50000] 2.25 sec(s) Train Acc: 0.849711 Loss: 0.046193 | Val Acc: 0.700000 loss: 0.079713\n",
      "[027/50000] 2.29 sec(s) Train Acc: 0.890173 Loss: 0.037574 | Val Acc: 0.750000 loss: 0.077507\n",
      "[028/50000] 2.24 sec(s) Train Acc: 0.884393 Loss: 0.035542 | Val Acc: 0.700000 loss: 0.073776\n",
      "[029/50000] 2.26 sec(s) Train Acc: 0.878613 Loss: 0.037550 | Val Acc: 0.700000 loss: 0.080284\n",
      "[030/50000] 2.27 sec(s) Train Acc: 0.884393 Loss: 0.040352 | Val Acc: 0.700000 loss: 0.077178\n",
      "[031/50000] 2.32 sec(s) Train Acc: 0.890173 Loss: 0.036584 | Val Acc: 0.650000 loss: 0.077513\n",
      "[032/50000] 2.24 sec(s) Train Acc: 0.809249 Loss: 0.051195 | Val Acc: 0.650000 loss: 0.095896\n",
      "[033/50000] 2.23 sec(s) Train Acc: 0.855491 Loss: 0.046715 | Val Acc: 0.700000 loss: 0.087687\n",
      "[034/50000] 2.21 sec(s) Train Acc: 0.884393 Loss: 0.038670 | Val Acc: 0.700000 loss: 0.089629\n",
      "[035/50000] 2.27 sec(s) Train Acc: 0.878613 Loss: 0.035240 | Val Acc: 0.700000 loss: 0.097319\n",
      "[036/50000] 2.26 sec(s) Train Acc: 0.855491 Loss: 0.038533 | Val Acc: 0.750000 loss: 0.073762\n",
      "[037/50000] 2.21 sec(s) Train Acc: 0.861272 Loss: 0.037859 | Val Acc: 0.750000 loss: 0.071027\n",
      "[038/50000] 2.28 sec(s) Train Acc: 0.872832 Loss: 0.040253 | Val Acc: 0.650000 loss: 0.078859\n",
      "[039/50000] 2.24 sec(s) Train Acc: 0.901734 Loss: 0.037877 | Val Acc: 0.750000 loss: 0.070485\n",
      "[040/50000] 2.26 sec(s) Train Acc: 0.884393 Loss: 0.031089 | Val Acc: 0.700000 loss: 0.068542\n",
      "[041/50000] 2.22 sec(s) Train Acc: 0.878613 Loss: 0.037170 | Val Acc: 0.650000 loss: 0.091820\n",
      "[042/50000] 2.27 sec(s) Train Acc: 0.884393 Loss: 0.034875 | Val Acc: 0.650000 loss: 0.084264\n",
      "[043/50000] 2.24 sec(s) Train Acc: 0.919075 Loss: 0.035314 | Val Acc: 0.700000 loss: 0.079900\n",
      "[044/50000] 2.23 sec(s) Train Acc: 0.872832 Loss: 0.034920 | Val Acc: 0.650000 loss: 0.114824\n",
      "[045/50000] 2.26 sec(s) Train Acc: 0.878613 Loss: 0.036981 | Val Acc: 0.750000 loss: 0.104093\n",
      "[046/50000] 2.19 sec(s) Train Acc: 0.872832 Loss: 0.039739 | Val Acc: 0.750000 loss: 0.088167\n",
      "[047/50000] 2.25 sec(s) Train Acc: 0.890173 Loss: 0.033863 | Val Acc: 0.650000 loss: 0.107545\n",
      "[048/50000] 2.23 sec(s) Train Acc: 0.901734 Loss: 0.033230 | Val Acc: 0.650000 loss: 0.068182\n",
      "[049/50000] 2.22 sec(s) Train Acc: 0.895954 Loss: 0.031830 | Val Acc: 0.800000 loss: 0.061974\n",
      "[050/50000] 2.17 sec(s) Train Acc: 0.867052 Loss: 0.046714 | Val Acc: 0.750000 loss: 0.071587\n",
      "[051/50000] 2.26 sec(s) Train Acc: 0.849711 Loss: 0.038362 | Val Acc: 0.700000 loss: 0.079363\n",
      "[052/50000] 2.23 sec(s) Train Acc: 0.895954 Loss: 0.031947 | Val Acc: 0.650000 loss: 0.084770\n",
      "[053/50000] 2.23 sec(s) Train Acc: 0.809249 Loss: 0.044781 | Val Acc: 0.650000 loss: 0.094029\n",
      "[054/50000] 2.32 sec(s) Train Acc: 0.878613 Loss: 0.048443 | Val Acc: 0.750000 loss: 0.065622\n",
      "[055/50000] 2.26 sec(s) Train Acc: 0.878613 Loss: 0.038553 | Val Acc: 0.750000 loss: 0.071944\n",
      "[056/50000] 2.28 sec(s) Train Acc: 0.884393 Loss: 0.034161 | Val Acc: 0.700000 loss: 0.086732\n",
      "[057/50000] 2.23 sec(s) Train Acc: 0.913295 Loss: 0.027211 | Val Acc: 0.700000 loss: 0.089491\n",
      "[058/50000] 2.29 sec(s) Train Acc: 0.878613 Loss: 0.037349 | Val Acc: 0.750000 loss: 0.077080\n",
      "[059/50000] 2.20 sec(s) Train Acc: 0.901734 Loss: 0.034123 | Val Acc: 0.750000 loss: 0.060163\n",
      "[060/50000] 2.15 sec(s) Train Acc: 0.901734 Loss: 0.033084 | Val Acc: 0.700000 loss: 0.066667\n",
      "[061/50000] 2.21 sec(s) Train Acc: 0.907514 Loss: 0.036137 | Val Acc: 0.800000 loss: 0.066100\n",
      "[062/50000] 2.17 sec(s) Train Acc: 0.895954 Loss: 0.029403 | Val Acc: 0.700000 loss: 0.071381\n",
      "[063/50000] 2.19 sec(s) Train Acc: 0.890173 Loss: 0.042433 | Val Acc: 0.650000 loss: 0.092656\n",
      "[064/50000] 2.25 sec(s) Train Acc: 0.872832 Loss: 0.037155 | Val Acc: 0.700000 loss: 0.070223\n",
      "[065/50000] 2.16 sec(s) Train Acc: 0.849711 Loss: 0.037571 | Val Acc: 0.750000 loss: 0.065590\n",
      "[066/50000] 2.16 sec(s) Train Acc: 0.849711 Loss: 0.044703 | Val Acc: 0.700000 loss: 0.085569\n",
      "[067/50000] 2.12 sec(s) Train Acc: 0.872832 Loss: 0.038258 | Val Acc: 0.700000 loss: 0.086877\n",
      "[068/50000] 2.24 sec(s) Train Acc: 0.924855 Loss: 0.035353 | Val Acc: 0.700000 loss: 0.088974\n",
      "[069/50000] 2.29 sec(s) Train Acc: 0.901734 Loss: 0.033290 | Val Acc: 0.700000 loss: 0.092722\n",
      "[070/50000] 2.21 sec(s) Train Acc: 0.890173 Loss: 0.033809 | Val Acc: 0.650000 loss: 0.103127\n",
      "[071/50000] 2.16 sec(s) Train Acc: 0.895954 Loss: 0.032846 | Val Acc: 0.750000 loss: 0.069235\n",
      "[072/50000] 2.23 sec(s) Train Acc: 0.855491 Loss: 0.039307 | Val Acc: 0.600000 loss: 0.175929\n",
      "[073/50000] 2.19 sec(s) Train Acc: 0.890173 Loss: 0.035885 | Val Acc: 0.700000 loss: 0.118552\n",
      "[074/50000] 2.20 sec(s) Train Acc: 0.907514 Loss: 0.031078 | Val Acc: 0.700000 loss: 0.105229\n",
      "[075/50000] 2.14 sec(s) Train Acc: 0.907514 Loss: 0.032652 | Val Acc: 0.750000 loss: 0.078239\n",
      "[076/50000] 2.15 sec(s) Train Acc: 0.878613 Loss: 0.038281 | Val Acc: 0.750000 loss: 0.075992\n",
      "[077/50000] 2.15 sec(s) Train Acc: 0.797688 Loss: 0.062972 | Val Acc: 0.800000 loss: 0.062303\n",
      "[078/50000] 2.21 sec(s) Train Acc: 0.843931 Loss: 0.044095 | Val Acc: 0.800000 loss: 0.063374\n",
      "[079/50000] 2.20 sec(s) Train Acc: 0.895954 Loss: 0.029319 | Val Acc: 0.750000 loss: 0.093245\n",
      "[080/50000] 2.29 sec(s) Train Acc: 0.919075 Loss: 0.030886 | Val Acc: 0.750000 loss: 0.090649\n",
      "[081/50000] 2.17 sec(s) Train Acc: 0.901734 Loss: 0.030605 | Val Acc: 0.750000 loss: 0.091794\n",
      "[082/50000] 2.18 sec(s) Train Acc: 0.867052 Loss: 0.038348 | Val Acc: 0.750000 loss: 0.086446\n",
      "[083/50000] 2.28 sec(s) Train Acc: 0.930636 Loss: 0.027353 | Val Acc: 0.700000 loss: 0.104378\n",
      "[084/50000] 2.26 sec(s) Train Acc: 0.861272 Loss: 0.038395 | Val Acc: 0.700000 loss: 0.123790\n",
      "[085/50000] 2.24 sec(s) Train Acc: 0.861272 Loss: 0.037740 | Val Acc: 0.700000 loss: 0.089001\n",
      "[086/50000] 2.26 sec(s) Train Acc: 0.878613 Loss: 0.031308 | Val Acc: 0.700000 loss: 0.084738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[087/50000] 2.27 sec(s) Train Acc: 0.890173 Loss: 0.036211 | Val Acc: 0.700000 loss: 0.107022\n",
      "[088/50000] 2.46 sec(s) Train Acc: 0.867052 Loss: 0.037478 | Val Acc: 0.600000 loss: 0.170990\n",
      "[089/50000] 2.25 sec(s) Train Acc: 0.878613 Loss: 0.042028 | Val Acc: 0.650000 loss: 0.106309\n",
      "[090/50000] 2.30 sec(s) Train Acc: 0.913295 Loss: 0.032169 | Val Acc: 0.750000 loss: 0.062038\n",
      "[091/50000] 2.36 sec(s) Train Acc: 0.901734 Loss: 0.033786 | Val Acc: 0.700000 loss: 0.101607\n",
      "[092/50000] 2.23 sec(s) Train Acc: 0.838150 Loss: 0.047392 | Val Acc: 0.650000 loss: 0.134383\n",
      "[093/50000] 2.29 sec(s) Train Acc: 0.867052 Loss: 0.038607 | Val Acc: 0.600000 loss: 0.118854\n",
      "[094/50000] 2.22 sec(s) Train Acc: 0.907514 Loss: 0.033947 | Val Acc: 0.700000 loss: 0.080873\n",
      "[095/50000] 2.22 sec(s) Train Acc: 0.913295 Loss: 0.034020 | Val Acc: 0.750000 loss: 0.068521\n",
      "[096/50000] 2.87 sec(s) Train Acc: 0.930636 Loss: 0.025757 | Val Acc: 0.700000 loss: 0.106641\n",
      "[097/50000] 2.44 sec(s) Train Acc: 0.872832 Loss: 0.036602 | Val Acc: 0.700000 loss: 0.111383\n",
      "[098/50000] 2.38 sec(s) Train Acc: 0.884393 Loss: 0.035774 | Val Acc: 0.750000 loss: 0.068040\n",
      "[099/50000] 2.20 sec(s) Train Acc: 0.907514 Loss: 0.032317 | Val Acc: 0.650000 loss: 0.124034\n",
      "[100/50000] 2.52 sec(s) Train Acc: 0.901734 Loss: 0.030856 | Val Acc: 0.600000 loss: 0.106383\n",
      "[101/50000] 2.52 sec(s) Train Acc: 0.884393 Loss: 0.032467 | Val Acc: 0.650000 loss: 0.066557\n",
      "[102/50000] 2.35 sec(s) Train Acc: 0.849711 Loss: 0.036102 | Val Acc: 0.700000 loss: 0.094038\n",
      "[103/50000] 2.23 sec(s) Train Acc: 0.867052 Loss: 0.039092 | Val Acc: 0.750000 loss: 0.068418\n",
      "[104/50000] 2.22 sec(s) Train Acc: 0.878613 Loss: 0.033385 | Val Acc: 0.700000 loss: 0.115024\n",
      "[105/50000] 2.24 sec(s) Train Acc: 0.907514 Loss: 0.027486 | Val Acc: 0.750000 loss: 0.065440\n",
      "[106/50000] 3.79 sec(s) Train Acc: 0.843931 Loss: 0.046601 | Val Acc: 0.650000 loss: 0.132075\n",
      "[107/50000] 2.40 sec(s) Train Acc: 0.895954 Loss: 0.035639 | Val Acc: 0.700000 loss: 0.078464\n",
      "[108/50000] 2.44 sec(s) Train Acc: 0.913295 Loss: 0.030706 | Val Acc: 0.700000 loss: 0.079158\n",
      "[109/50000] 2.52 sec(s) Train Acc: 0.890173 Loss: 0.035953 | Val Acc: 0.650000 loss: 0.093523\n",
      "[110/50000] 2.57 sec(s) Train Acc: 0.867052 Loss: 0.040428 | Val Acc: 0.650000 loss: 0.109529\n",
      "[111/50000] 2.39 sec(s) Train Acc: 0.872832 Loss: 0.044582 | Val Acc: 0.700000 loss: 0.114068\n",
      "[112/50000] 2.32 sec(s) Train Acc: 0.913295 Loss: 0.028424 | Val Acc: 0.750000 loss: 0.064849\n",
      "[113/50000] 2.19 sec(s) Train Acc: 0.872832 Loss: 0.036144 | Val Acc: 0.650000 loss: 0.092878\n",
      "[114/50000] 2.20 sec(s) Train Acc: 0.907514 Loss: 0.032093 | Val Acc: 0.650000 loss: 0.138482\n",
      "[115/50000] 2.23 sec(s) Train Acc: 0.913295 Loss: 0.029133 | Val Acc: 0.650000 loss: 0.130156\n",
      "[116/50000] 2.12 sec(s) Train Acc: 0.907514 Loss: 0.033193 | Val Acc: 0.600000 loss: 0.147074\n",
      "[117/50000] 2.25 sec(s) Train Acc: 0.843931 Loss: 0.050114 | Val Acc: 0.750000 loss: 0.104133\n",
      "[118/50000] 2.18 sec(s) Train Acc: 0.884393 Loss: 0.031040 | Val Acc: 0.600000 loss: 0.114050\n",
      "[119/50000] 2.16 sec(s) Train Acc: 0.843931 Loss: 0.046017 | Val Acc: 0.650000 loss: 0.120718\n",
      "[120/50000] 2.23 sec(s) Train Acc: 0.890173 Loss: 0.030448 | Val Acc: 0.550000 loss: 0.186673\n",
      "[121/50000] 2.22 sec(s) Train Acc: 0.843931 Loss: 0.049096 | Val Acc: 0.700000 loss: 0.089392\n",
      "[122/50000] 2.17 sec(s) Train Acc: 0.895954 Loss: 0.032042 | Val Acc: 0.700000 loss: 0.091298\n",
      "[123/50000] 2.13 sec(s) Train Acc: 0.890173 Loss: 0.026127 | Val Acc: 0.650000 loss: 0.113367\n",
      "[124/50000] 2.23 sec(s) Train Acc: 0.936416 Loss: 0.020827 | Val Acc: 0.650000 loss: 0.087275\n",
      "[125/50000] 2.18 sec(s) Train Acc: 0.913295 Loss: 0.027399 | Val Acc: 0.650000 loss: 0.098723\n",
      "[126/50000] 2.19 sec(s) Train Acc: 0.913295 Loss: 0.031026 | Val Acc: 0.700000 loss: 0.099658\n",
      "[127/50000] 2.15 sec(s) Train Acc: 0.884393 Loss: 0.048430 | Val Acc: 0.700000 loss: 0.120410\n",
      "[128/50000] 2.15 sec(s) Train Acc: 0.867052 Loss: 0.039386 | Val Acc: 0.700000 loss: 0.080997\n",
      "[129/50000] 2.22 sec(s) Train Acc: 0.878613 Loss: 0.037241 | Val Acc: 0.750000 loss: 0.068128\n",
      "[130/50000] 2.18 sec(s) Train Acc: 0.907514 Loss: 0.036913 | Val Acc: 0.650000 loss: 0.095670\n",
      "[131/50000] 2.23 sec(s) Train Acc: 0.878613 Loss: 0.040577 | Val Acc: 0.700000 loss: 0.090544\n",
      "[132/50000] 2.18 sec(s) Train Acc: 0.924855 Loss: 0.027981 | Val Acc: 0.800000 loss: 0.061838\n",
      "[133/50000] 2.14 sec(s) Train Acc: 0.838150 Loss: 0.046293 | Val Acc: 0.650000 loss: 0.109436\n",
      "[134/50000] 2.21 sec(s) Train Acc: 0.884393 Loss: 0.030254 | Val Acc: 0.700000 loss: 0.097931\n",
      "[135/50000] 2.28 sec(s) Train Acc: 0.936416 Loss: 0.027501 | Val Acc: 0.700000 loss: 0.098531\n",
      "[136/50000] 2.23 sec(s) Train Acc: 0.890173 Loss: 0.031050 | Val Acc: 0.550000 loss: 0.156593\n",
      "[137/50000] 2.23 sec(s) Train Acc: 0.878613 Loss: 0.044050 | Val Acc: 0.550000 loss: 0.201538\n",
      "[138/50000] 2.17 sec(s) Train Acc: 0.884393 Loss: 0.031794 | Val Acc: 0.800000 loss: 0.064275\n",
      "[139/50000] 2.17 sec(s) Train Acc: 0.907514 Loss: 0.029318 | Val Acc: 0.750000 loss: 0.064656\n",
      "[140/50000] 2.17 sec(s) Train Acc: 0.884393 Loss: 0.035088 | Val Acc: 0.600000 loss: 0.140632\n",
      "[141/50000] 2.14 sec(s) Train Acc: 0.919075 Loss: 0.026191 | Val Acc: 0.700000 loss: 0.089711\n",
      "[142/50000] 2.18 sec(s) Train Acc: 0.901734 Loss: 0.029778 | Val Acc: 0.700000 loss: 0.091542\n",
      "[143/50000] 2.16 sec(s) Train Acc: 0.878613 Loss: 0.039632 | Val Acc: 0.800000 loss: 0.066294\n",
      "[144/50000] 2.26 sec(s) Train Acc: 0.820809 Loss: 0.054181 | Val Acc: 0.650000 loss: 0.085201\n",
      "[145/50000] 2.20 sec(s) Train Acc: 0.861272 Loss: 0.039494 | Val Acc: 0.700000 loss: 0.113505\n",
      "[146/50000] 2.18 sec(s) Train Acc: 0.878613 Loss: 0.042853 | Val Acc: 0.550000 loss: 0.206717\n",
      "[147/50000] 2.16 sec(s) Train Acc: 0.861272 Loss: 0.040637 | Val Acc: 0.600000 loss: 0.139706\n",
      "[148/50000] 2.25 sec(s) Train Acc: 0.872832 Loss: 0.030302 | Val Acc: 0.650000 loss: 0.103303\n",
      "[149/50000] 2.19 sec(s) Train Acc: 0.913295 Loss: 0.025091 | Val Acc: 0.750000 loss: 0.094700\n",
      "[150/50000] 2.19 sec(s) Train Acc: 0.919075 Loss: 0.030014 | Val Acc: 0.650000 loss: 0.082037\n",
      "[151/50000] 2.19 sec(s) Train Acc: 0.895954 Loss: 0.036310 | Val Acc: 0.700000 loss: 0.112309\n",
      "[152/50000] 2.21 sec(s) Train Acc: 0.907514 Loss: 0.023028 | Val Acc: 0.650000 loss: 0.127353\n",
      "[153/50000] 2.19 sec(s) Train Acc: 0.872832 Loss: 0.035490 | Val Acc: 0.650000 loss: 0.139044\n",
      "[154/50000] 2.25 sec(s) Train Acc: 0.901734 Loss: 0.036611 | Val Acc: 0.700000 loss: 0.141554\n",
      "[155/50000] 2.19 sec(s) Train Acc: 0.919075 Loss: 0.026564 | Val Acc: 0.650000 loss: 0.151563\n",
      "[156/50000] 2.78 sec(s) Train Acc: 0.913295 Loss: 0.028474 | Val Acc: 0.700000 loss: 0.094986\n",
      "[157/50000] 2.33 sec(s) Train Acc: 0.895954 Loss: 0.036969 | Val Acc: 0.700000 loss: 0.094316\n",
      "[158/50000] 2.28 sec(s) Train Acc: 0.878613 Loss: 0.035673 | Val Acc: 0.650000 loss: 0.130853\n",
      "[159/50000] 2.20 sec(s) Train Acc: 0.895954 Loss: 0.030979 | Val Acc: 0.700000 loss: 0.107096\n",
      "[160/50000] 2.23 sec(s) Train Acc: 0.901734 Loss: 0.028304 | Val Acc: 0.750000 loss: 0.107530\n",
      "[161/50000] 2.18 sec(s) Train Acc: 0.895954 Loss: 0.031936 | Val Acc: 0.650000 loss: 0.124721\n",
      "[162/50000] 2.27 sec(s) Train Acc: 0.901734 Loss: 0.030643 | Val Acc: 0.700000 loss: 0.110966\n",
      "[163/50000] 2.19 sec(s) Train Acc: 0.890173 Loss: 0.035484 | Val Acc: 0.700000 loss: 0.124742\n",
      "[164/50000] 2.22 sec(s) Train Acc: 0.861272 Loss: 0.036430 | Val Acc: 0.700000 loss: 0.077218\n",
      "[165/50000] 2.17 sec(s) Train Acc: 0.890173 Loss: 0.038635 | Val Acc: 0.650000 loss: 0.150332\n",
      "[166/50000] 2.29 sec(s) Train Acc: 0.884393 Loss: 0.031697 | Val Acc: 0.700000 loss: 0.131724\n",
      "[167/50000] 2.18 sec(s) Train Acc: 0.913295 Loss: 0.030433 | Val Acc: 0.650000 loss: 0.091182\n",
      "[168/50000] 2.10 sec(s) Train Acc: 0.907514 Loss: 0.030538 | Val Acc: 0.750000 loss: 0.107483\n",
      "[169/50000] 2.52 sec(s) Train Acc: 0.942197 Loss: 0.024278 | Val Acc: 0.700000 loss: 0.121109\n",
      "[170/50000] 2.28 sec(s) Train Acc: 0.884393 Loss: 0.029726 | Val Acc: 0.650000 loss: 0.096460\n",
      "[171/50000] 2.14 sec(s) Train Acc: 0.895954 Loss: 0.036519 | Val Acc: 0.700000 loss: 0.100582\n",
      "[172/50000] 2.24 sec(s) Train Acc: 0.913295 Loss: 0.039489 | Val Acc: 0.650000 loss: 0.129789\n",
      "[173/50000] 2.22 sec(s) Train Acc: 0.919075 Loss: 0.027560 | Val Acc: 0.650000 loss: 0.145566\n",
      "[174/50000] 2.23 sec(s) Train Acc: 0.878613 Loss: 0.031312 | Val Acc: 0.700000 loss: 0.176482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[175/50000] 2.56 sec(s) Train Acc: 0.895954 Loss: 0.040500 | Val Acc: 0.650000 loss: 0.148816\n",
      "[176/50000] 2.75 sec(s) Train Acc: 0.924855 Loss: 0.023861 | Val Acc: 0.650000 loss: 0.109176\n",
      "[177/50000] 2.30 sec(s) Train Acc: 0.924855 Loss: 0.030696 | Val Acc: 0.700000 loss: 0.090217\n",
      "[178/50000] 2.33 sec(s) Train Acc: 0.872832 Loss: 0.039850 | Val Acc: 0.750000 loss: 0.089835\n",
      "[179/50000] 2.32 sec(s) Train Acc: 0.884393 Loss: 0.037322 | Val Acc: 0.700000 loss: 0.126083\n",
      "[180/50000] 2.52 sec(s) Train Acc: 0.924855 Loss: 0.030585 | Val Acc: 0.700000 loss: 0.112770\n",
      "[181/50000] 2.47 sec(s) Train Acc: 0.913295 Loss: 0.032463 | Val Acc: 0.700000 loss: 0.114394\n",
      "[182/50000] 2.43 sec(s) Train Acc: 0.890173 Loss: 0.039228 | Val Acc: 0.550000 loss: 0.200505\n",
      "[183/50000] 2.43 sec(s) Train Acc: 0.907514 Loss: 0.032404 | Val Acc: 0.750000 loss: 0.100458\n",
      "[184/50000] 2.30 sec(s) Train Acc: 0.919075 Loss: 0.025889 | Val Acc: 0.750000 loss: 0.088227\n",
      "[185/50000] 2.21 sec(s) Train Acc: 0.919075 Loss: 0.026652 | Val Acc: 0.650000 loss: 0.115677\n",
      "[186/50000] 2.18 sec(s) Train Acc: 0.919075 Loss: 0.027146 | Val Acc: 0.700000 loss: 0.120804\n",
      "[187/50000] 2.23 sec(s) Train Acc: 0.890173 Loss: 0.038971 | Val Acc: 0.750000 loss: 0.072777\n",
      "[188/50000] 2.14 sec(s) Train Acc: 0.867052 Loss: 0.037634 | Val Acc: 0.750000 loss: 0.118348\n",
      "[189/50000] 2.26 sec(s) Train Acc: 0.878613 Loss: 0.041847 | Val Acc: 0.650000 loss: 0.183711\n",
      "[190/50000] 2.26 sec(s) Train Acc: 0.791908 Loss: 0.054729 | Val Acc: 0.550000 loss: 0.210689\n",
      "[191/50000] 2.44 sec(s) Train Acc: 0.855491 Loss: 0.041171 | Val Acc: 0.500000 loss: 0.204496\n",
      "[192/50000] 2.24 sec(s) Train Acc: 0.878613 Loss: 0.038256 | Val Acc: 0.650000 loss: 0.182930\n",
      "[193/50000] 2.27 sec(s) Train Acc: 0.913295 Loss: 0.031053 | Val Acc: 0.600000 loss: 0.176966\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-c80413aad9dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 確保 model 是在 train model (開啟 Dropout 等...)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 用 optimizer 將 model 參數的 gradient 歸零\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mtrain_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 利用 model 得到預測的機率分佈 這邊實際上就是去呼叫 model 的 forward 函數\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-c80413aad9dd>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \"\"\"\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m     \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import需要的套件\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import time\n",
    "import torchvision\n",
    "\n",
    "\n",
    "\n",
    "def readfile(path, label):\n",
    "    # label 是一個 boolean variable，代表需不需要回傳 y 值\n",
    "    image_dir = sorted(os.listdir(path))\n",
    "    x = np.zeros((len(image_dir), 224, 224, 3), dtype=np.uint8)\n",
    "    y = np.zeros((len(image_dir)), dtype=np.uint8)\n",
    "    for i, file in enumerate(image_dir):\n",
    "        img = cv2.imread(os.path.join(path, file))\n",
    "        #resize\n",
    "        x[i, :, :] = cv2.resize(img,(224, 224))\n",
    "        if label:\n",
    "            y[i] = int(file.split(\"_\")[0])\n",
    "    if label:\n",
    "        return x, y\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "#分別將 training set、validation set、testing set 用 readfile 函式讀進來\n",
    "'''\n",
    "train_x = np.load('train_x_224.npy')\n",
    "train_y = np.load('train_y_224.npy')\n",
    "val_x = np.load('val_x_224.npy')\n",
    "val_y = np.load('val_y_224.npy')\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "#training 時做 data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(), #隨機將圖片水平翻轉\n",
    "    transforms.RandomRotation(45), #隨機旋轉圖片\n",
    "    transforms.RandomRotation(15), #隨機旋轉圖片\n",
    "    transforms.ToTensor(), #將圖片轉成 Tensor，並把數值normalize到[0,1](data normalization)\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "#testing 時不需做 data augmentation\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                                    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, x, y=None, transform=None):\n",
    "        self.x = x\n",
    "        # label is required to be a LongTensor\n",
    "        self.y = y\n",
    "        if y is not None:\n",
    "            self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, index):\n",
    "        X = self.x[index]\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        if self.y is not None:\n",
    "            Y = self.y[index]\n",
    "            return X, Y\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "batch_size = 8\n",
    "train_set = ImgDataset(train_x, train_y, train_transform)\n",
    "val_set = ImgDataset(val_x, val_y, test_transform)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "#original_model = torchvision.models.resnet50(pretrained = True)\n",
    "#original_model = torchvision.models.googlenet(pretrained=True)\n",
    "#original_model = torchvision.models.densenet121(pretrained=True)#batch size 200\n",
    "#original_model = torchvision.models.resnext101_32x8d(pretrained=True)#batch_size = 96\n",
    "#original_model = torchvision.models.wide_resnet101_2(pretrained=True)#batch_size = 72\n",
    "model = torchvision.models.mobilenet_v2(pretrained=True)#batch size 200\n",
    "#model = torchvision.models.mobilenet_v2(pretrained = True)\n",
    "print(model)\n",
    "\n",
    "#model = original_model\n",
    "model.classifier = nn.Sequential(\n",
    "                    nn.Linear(1280,11),\n",
    "                    #nn.Dropout(0.3),\n",
    "                    #nn.ReLU(),\n",
    "                    #nn.Linear(1024,512),\n",
    "                    #nn.Dropout(0.25),\n",
    "                    #nn.ReLU(),\n",
    "                    #nn.Linear(512, 11),\n",
    "                    )\n",
    "#model = Classifier()\n",
    "#model.load_state_dict(torch.load('./model/densenet161_819534.pth'))\n",
    "model.cuda()\n",
    "\n",
    "loss = nn.CrossEntropyLoss() # 因為是 classification task，所以 loss 使用 CrossEntropyLoss\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.002) # optimizer 使用 Adam\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001, betas=[0.9, 0.999])\n",
    "num_epoch = 50000\n",
    "\n",
    "best_val_acc = 0\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    model.train() # 確保 model 是在 train model (開啟 Dropout 等...)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad() # 用 optimizer 將 model 參數的 gradient 歸零\n",
    "        train_pred = model(data[0].cuda()) # 利用 model 得到預測的機率分佈 這邊實際上就是去呼叫 model 的 forward 函數\n",
    "        batch_loss = loss(train_pred, data[1].cuda()) # 計算 loss （注意 prediction 跟 label 必須同時在 CPU 或是 GPU 上）\n",
    "        batch_loss.backward() # 利用 back propagation 算出每個參數的 gradient\n",
    "        optimizer.step() # 以 optimizer 用 gradient 更新參數值\n",
    "\n",
    "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "        train_loss += batch_loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            val_pred = model(data[0].cuda())\n",
    "            batch_loss = loss(val_pred, data[1].cuda())\n",
    "\n",
    "            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "            val_loss += batch_loss.item()\n",
    "\n",
    "        final_train_acc = train_acc/train_set.__len__()\n",
    "        final_val_acc = val_acc/val_set.__len__()\n",
    "        #if (final_train_acc > 0.95 and final_val_acc > best_val_acc):\n",
    "        if (final_val_acc > best_val_acc):\n",
    "            best_val_acc = final_val_acc\n",
    "            #print(\"------: \", train_acc/train_set.__len__())\n",
    "            #checkpoint_path = './model/model_{}_acc_{}.pth'.format(epoch+1,best_val_acc) \n",
    "            checkpoint_path = './model/model_best_densenet161.pth' \n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print('model saved to %s' % checkpoint_path)\n",
    "        \n",
    "        #將結果 print 出來\n",
    "        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f' % \\\n",
    "            (epoch + 1, num_epoch, time.time()-epoch_start_time, \\\n",
    "             train_acc/train_set.__len__(), train_loss/train_set.__len__(), val_acc/val_set.__len__(), val_loss/val_set.__len__()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
